{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Driver code comparing output of different preproc pipelines \n",
    "- Note: currently using output after atlas-based grouping\n",
    "- Atlas used: aparc (Freesurfer) DKT-31 Mindboggle (ANTs: https://mindboggle.readthedocs.io/en/latest/labels.html) \n",
    "\n",
    "### Steps\n",
    "- import data csvs \n",
    "- visualize data distributions \n",
    "- correlate features across pipelines\n",
    "- compare performance of machine-learning model (scikit-learn)\n",
    "- compare performance of statsmodels (ols or logit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import itertools\n",
    "\n",
    "from sklearn import svm\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "sys.path.append('../')\n",
    "from lib.data_handling import *\n",
    "from lib.data_stats import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#proj_dir = '/Users/nikhil/code/git_repos/compare-surf-tools/'\n",
    "proj_dir = '/Users/nikhil/projects/compare-surf-tools/'\n",
    "data_dir = proj_dir + 'data/'\n",
    "fs60_dir = data_dir + 'fs60_group_stats/'\n",
    "results_dir = data_dir + 'results/'\n",
    "\n",
    "demograph_file = 'ABIDE_Phenotype.csv'\n",
    "dkt_roi_names = 'DKT_parcel_map_FS_CIVET.csv'\n",
    "\n",
    "ants_file = 'ABIDE_ants_thickness_data.csv' #uses modified (mindboggle) dkt atlas with 31 ROIs\n",
    "civet_file = 'ABIDE_civet2.1_thickness.csv'\n",
    "\n",
    "fs53_file = 'ABIDE_fs5.3_thickness.csv'\n",
    "fs51_file = 'cortical_fs5.1_measuresenigma_thickavg.csv' \n",
    "fs60_lh_file = 'lh.aparc.thickness.table.test1' #'aparc_lh_thickness_table.txt' #'lh.aparc.thickness.table.test1'\n",
    "fs60_rh_file = 'rh.aparc.thickness.table.test1' #'aparc_rh_thickness_table.txt' #'rh.aparc.thickness.table.test1'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Global Vars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "subject_ID_col = 'SubjID'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of civet data (3, 65)\n",
      "shape of stdized civet data (3, 65)\n",
      "\n",
      "shape of ants data (1101, 99)\n",
      "shape of stdized ants data (1101, 90)\n",
      "\n",
      "shape of fs53 data (976, 74)\n",
      "shape of stdized fs53 data (976, 74)\n",
      "\n",
      "shape of fs51 data (1112, 74)\n",
      "shape of stdized fs51 data (1112, 74)\n",
      "\n",
      "shape of fs60 data l: (1047, 36), r: (1047, 36)\n",
      "shape of left and right merge fs6.0 df (1047, 71)\n",
      "shape of stdized fs51 data (1047, 71)\n"
     ]
    }
   ],
   "source": [
    "# Demographics and Dx\n",
    "demograph = pd.read_csv(data_dir + demograph_file)\n",
    "demograph = demograph.rename(columns={'Subject_ID':subject_ID_col})\n",
    "\n",
    "# ROI names\n",
    "dkt_roi_map = pd.read_csv(data_dir + dkt_roi_names)\n",
    "\n",
    "# CIVET 2.1\n",
    "civet_data = pd.read_csv(data_dir + civet_file)\n",
    "print('shape of civet data {}'.format(civet_data.shape))\n",
    "civet_data_std = standardize_civet_data(civet_data, subject_ID_col, dkt_roi_map)\n",
    "print('shape of stdized civet data {}'.format(civet_data_std.shape))\n",
    "print('')\n",
    "\n",
    "# ANTs\n",
    "ants_data = pd.read_csv(data_dir + ants_file, header=2)\n",
    "print('shape of ants data {}'.format(ants_data.shape))\n",
    "ants_data_std = standardize_ants_data(ants_data, subject_ID_col)\n",
    "print('shape of stdized ants data {}'.format(ants_data_std.shape))\n",
    "print('')\n",
    "\n",
    "# FS\n",
    "fs53_data = pd.read_csv(data_dir + fs53_file)\n",
    "print('shape of fs53 data {}'.format(fs53_data.shape))\n",
    "fs53_data_std = standardize_fs_data(fs53_data, subject_ID_col)\n",
    "print('shape of stdized fs53 data {}'.format(fs53_data_std.shape))\n",
    "print('')\n",
    "\n",
    "fs51_data = pd.read_csv(data_dir + fs51_file)\n",
    "print('shape of fs51 data {}'.format(fs51_data.shape))\n",
    "fs51_data_std = standardize_fs_data(fs51_data, subject_ID_col)\n",
    "print('shape of stdized fs51 data {}'.format(fs51_data_std.shape))\n",
    "print('')\n",
    "\n",
    "fs60_lh_data = pd.read_csv(fs60_dir + fs60_lh_file, delim_whitespace=True)\n",
    "fs60_rh_data = pd.read_csv(fs60_dir + fs60_rh_file, delim_whitespace=True)\n",
    "print('shape of fs60 data l: {}, r: {}'.format(fs60_lh_data.shape,fs60_rh_data.shape))\n",
    "\n",
    "fs60_data_std = standardize_fs60_data(fs60_lh_data, fs60_rh_data, subject_ID_col)\n",
    "print('shape of stdized fs51 data {}'.format(fs60_data_std.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create master dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of datasets: 5\n",
      "Finding common subject and columns\n",
      "dataset : civet\n",
      "common subs: 3\n",
      "dataset : ants\n",
      "common subs: 0\n",
      "dataset : fs60\n",
      "common subs: 1047\n",
      "dataset : fs53\n",
      "common subs: 942\n",
      "dataset : fs51\n",
      "common subs: 942\n",
      "Number of common subjects and columns: 942, 63\n",
      "\n",
      "checking civet dataframe\n",
      "Shape of the dataframe based on common cols and subs (3, 63)\n",
      "Basic data check passed\n",
      "Shape of the concat dataframe (3, 64)\n",
      "\n",
      "checking ants dataframe\n",
      "Shape of the dataframe based on common cols and subs (941, 63)\n",
      "Basic data check passed\n",
      "Shape of the concat dataframe (944, 64)\n",
      "\n",
      "checking fs60 dataframe\n",
      "Shape of the dataframe based on common cols and subs (942, 63)\n",
      "Basic data check passed\n",
      "Shape of the concat dataframe (1886, 64)\n",
      "\n",
      "checking fs53 dataframe\n",
      "Shape of the dataframe based on common cols and subs (942, 63)\n",
      "Basic data check passed\n",
      "Shape of the concat dataframe (2828, 64)\n",
      "\n",
      "checking fs51 dataframe\n",
      "Shape of the dataframe based on common cols and subs (942, 63)\n",
      "Basic data check passed\n",
      "Shape of the concat dataframe (3770, 64)\n",
      "\n",
      "Number of common ROIs 62\n",
      "\n",
      "master df shape after adding demographic info (3770, 68)\n"
     ]
    }
   ],
   "source": [
    "data_dict = {'civet': civet_data_std,\n",
    "            'ants' : ants_data_std,\n",
    "            'fs60' : fs60_data_std,\n",
    "            'fs53' : fs53_data_std,\n",
    "            'fs51' : fs51_data_std}\n",
    "\n",
    "na_action = 'drop' # options: ignore, drop; anything else will not use the dataframe for analysis. \n",
    "master_df, common_subs, common_roi_cols = combine_processed_data(data_dict, subject_ID_col, na_action)\n",
    "\n",
    "print('\\nNumber of common ROIs {}'.format(len(common_roi_cols)))\n",
    "\n",
    "# Add demographic columns to the master_df\n",
    "useful_demograph = demograph[[subject_ID_col,'SEX','AGE_AT_SCAN','DX_GROUP','SITE_ID']].copy()\n",
    "\n",
    "# Shift to (0 and 1 instead of 1 and 2 for statsmodels)\n",
    "useful_demograph['DX_GROUP'] = useful_demograph['DX_GROUP']-1\n",
    "useful_demograph['SEX'] = useful_demograph['SEX']-1\n",
    "_,useful_demograph[subject_ID_col] = useful_demograph[subject_ID_col].str.rsplit('_', 1).str\n",
    "\n",
    "master_df = pd.merge(master_df, useful_demograph, how='left', on=subject_ID_col)\n",
    "print('\\nmaster df shape after adding demographic info {}'.format(master_df.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Correlation between pipelines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg cross correlation between fs51 & ants = 0.43\n",
      "\n",
      "Avg cross correlation between fs51 & fs53 = 0.89\n",
      "\n",
      "Avg cross correlation between fs51 & fs60 = 0.86\n",
      "\n",
      "Avg cross correlation between ants & fs53 = 0.47\n",
      "\n",
      "Avg cross correlation between ants & fs60 = 0.43\n",
      "\n",
      "Avg cross correlation between fs53 & fs60 = 0.91\n",
      "\n"
     ]
    }
   ],
   "source": [
    "possible_pairs = list(itertools.combinations(data_dict.keys(), 2))\n",
    "\n",
    "for pair in possible_pairs:\n",
    "    pipe1 = pair[0]\n",
    "    pipe2 = pair[1]\n",
    "    df1 = master_df[master_df['pipeline']==pipe1][[subject_ID_col]+common_roi_cols]\n",
    "    df2 = master_df[master_df['pipeline']==pipe2][[subject_ID_col]+common_roi_cols]\n",
    "\n",
    "    xcorr = cross_correlations(df1,df2,subject_ID_col)\n",
    "    print('Avg cross correlation between {} & {} = {:4.2f}\\n'.format(pipe1,pipe2,np.mean(xcorr)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compare ML performance "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running ML classifer on 4 pipelines\n",
      "Pipeline fs60\n",
      "Data shapes X (941, 62), y 941 ([506, 435])\n",
      "Using classification model with perf metric roc_auc\n",
      " Perf mean:0.566, sd:0.059\n",
      "Pipeline ants\n",
      "Data shapes X (941, 62), y 941 ([506, 435])\n",
      "Using classification model with perf metric roc_auc\n",
      " Perf mean:0.577, sd:0.046\n",
      "Pipeline fs51\n",
      "Data shapes X (941, 62), y 941 ([506, 435])\n",
      "Using classification model with perf metric roc_auc\n",
      " Perf mean:0.545, sd:0.059\n",
      "Pipeline fs53\n",
      "Data shapes X (941, 62), y 941 ([506, 435])\n",
      "Using classification model with perf metric roc_auc\n",
      " Perf mean:0.545, sd:0.053\n"
     ]
    }
   ],
   "source": [
    "roi_cols = common_roi_cols\n",
    "covar_continuous_cols = [] #'AGE_AT_SCAN'\n",
    "covar_cat_cols = [] #'SEX','SITE_ID','DX_GROUP'\n",
    "\n",
    "model_type = 'classification'\n",
    "\n",
    "if model_type.lower() == 'regression':\n",
    "    outcome_col = 'AGE_AT_SCAN'\n",
    "    model = RandomForestRegressor(max_depth=2, random_state=0, n_estimators=100)\n",
    "else: \n",
    "    outcome_col = 'DX_GROUP'\n",
    "    model = svm.SVC(kernel='linear')\n",
    "    #model = RandomForestClassifier(n_estimators=50, max_depth=2,random_state=0)\n",
    "\n",
    "ml_perf = computePipelineMLModels(master_df,roi_cols,covar_continuous_cols,covar_cat_cols,outcome_col,\n",
    "                                  model_type,model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Compare statsmodels performance "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running 62 mass-univariate logit statsmodels on 4 pipelines\n",
      "Pipeline fs51\n",
      "Example statsmodel run:\n",
      " DX_GROUP ~ R_precentral + AGE_AT_SCAN + C(SEX) + C(SITE_ID)\n",
      "Top 10 significant regions:\n",
      "                        roi     t_val     p_val pipeline\n",
      "12               L_lingual -3.198658  0.001381     fs51\n",
      "8   L_rostralmiddlefrontal -2.978978  0.002892     fs51\n",
      "48               R_lingual -2.968617  0.002991     fs51\n",
      "54      L_lateraloccipital -2.962219  0.003054     fs51\n",
      "17                L_cuneus -2.919661  0.003504     fs51\n",
      "50    L_posteriorcingulate -2.914745  0.003560     fs51\n",
      "1       R_lateraloccipital -2.862227  0.004207     fs51\n",
      "33         L_pericalcarine -2.675520  0.007461     fs51\n",
      "58           R_postcentral -2.653052  0.007977     fs51\n",
      "55  R_rostralmiddlefrontal -2.580449  0.009867     fs51\n",
      "Pipeline ants\n",
      "Example statsmodel run:\n",
      " DX_GROUP ~ R_precentral + AGE_AT_SCAN + C(SEX) + C(SITE_ID)\n",
      "Top 10 significant regions:\n",
      "                        roi     t_val     p_val pipeline\n",
      "41            L_precentral  3.240086  0.001195     ants\n",
      "61            R_precentral  3.006779  0.002640     ants\n",
      "55  R_rostralmiddlefrontal -2.742342  0.006100     ants\n",
      "39                L_insula  2.655011  0.007931     ants\n",
      "32                R_insula  2.623003  0.008716     ants\n",
      "52           R_paracentral  2.620875  0.008770     ants\n",
      "53   L_medialorbitofrontal -2.441159  0.014640     ants\n",
      "9       R_superiorparietal  2.335489  0.019518     ants\n",
      "56        R_middletemporal -2.221835  0.026294     ants\n",
      "15      L_superiorparietal  2.212071  0.026962     ants\n",
      "Pipeline fs53\n",
      "Example statsmodel run:\n",
      " DX_GROUP ~ R_precentral + AGE_AT_SCAN + C(SEX) + C(SITE_ID)\n",
      "Top 10 significant regions:\n",
      "                        roi     t_val     p_val pipeline\n",
      "48               R_lingual -3.061742  0.002201     fs53\n",
      "33         L_pericalcarine -2.868216  0.004128     fs53\n",
      "53   L_medialorbitofrontal -2.786514  0.005328     fs53\n",
      "50    L_posteriorcingulate -2.372719  0.017658     fs53\n",
      "52           R_paracentral  2.359979  0.018276     fs53\n",
      "17                L_cuneus -2.222919  0.026221     fs53\n",
      "12               L_lingual -2.221797  0.026297     fs53\n",
      "8   L_rostralmiddlefrontal -2.074156  0.038065     fs53\n",
      "16    L_transversetemporal -2.067997  0.038640     fs53\n",
      "54      L_lateraloccipital -1.969405  0.048907     fs53\n",
      "Pipeline fs60\n",
      "Example statsmodel run:\n",
      " DX_GROUP ~ R_precentral + AGE_AT_SCAN + C(SEX) + C(SITE_ID)\n",
      "Top 10 significant regions:\n",
      "                       roi     t_val     p_val pipeline\n",
      "48              R_lingual -3.747543  0.000179     fs60\n",
      "12              L_lingual -3.433293  0.000596     fs60\n",
      "33        L_pericalcarine -3.349924  0.000808     fs60\n",
      "53  L_medialorbitofrontal -3.318485  0.000905     fs60\n",
      "54     L_lateraloccipital -2.898741  0.003747     fs60\n",
      "17               L_cuneus -2.714935  0.006629     fs60\n",
      "1      R_lateraloccipital -2.613441  0.008964     fs60\n",
      "52          R_paracentral  2.563598  0.010359     fs60\n",
      "61           R_precentral  2.433784  0.014942     fs60\n",
      "50   L_posteriorcingulate -2.395371  0.016604     fs60\n",
      "Shape of the stats_models results df (248, 4)\n",
      "Saving sm_perf dictionary at \n",
      "/home/nikhil/projects/CT_reproduce/code/compare-surf-tools/data/results/pipelines_sm_perf_DX_GROUP.pkl\n"
     ]
    }
   ],
   "source": [
    "save_sm_perf = False\n",
    "roi_cols = common_roi_cols\n",
    "covar_continuous_cols = ['AGE_AT_SCAN']\n",
    "covar_cat_cols = ['SEX','SITE_ID']\n",
    "outcome_col = 'DX_GROUP' #AGE_AT_SCAN #DX_GROUP #SEX\n",
    "stat_model = 'logit' #ols #logit\n",
    "\n",
    "sm_perf = computePipelineStatsModels(master_df,roi_cols,covar_continuous_cols,covar_cat_cols,\n",
    "                                     outcome_col,stat_model)\n",
    "print('Shape of the stats_models results df {}'.format(sm_perf.shape))\n",
    "\n",
    "if save_sm_perf:\n",
    "    save_path = '{}pipelines_sm_perf_{}.pkl'.format(results_dir,outcome_col)\n",
    "    print('Saving sm_perf dictionary at \\n{}'.format(save_path))\n",
    "    sm_perf.to_pickle(save_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
