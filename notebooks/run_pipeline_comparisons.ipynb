{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Driver code comparing output of different preproc pipelines \n",
    "- Note: currently using output after atlas-based grouping\n",
    "- Atlas used: aparc (Freesurfer) DKT-31 Mindboggle (ANTs: https://mindboggle.readthedocs.io/en/latest/labels.html) \n",
    "\n",
    "### Steps\n",
    "- import data csvs \n",
    "- visualize data distributions \n",
    "- correlate features across pipelines\n",
    "- compare performance of machine-learning model (scikit-learn)\n",
    "- compare performance of statsmodels (ols or logit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import itertools\n",
    "from sklearn import svm\n",
    "\n",
    "sys.path.append('../')\n",
    "from lib.data_handling import *\n",
    "from lib.data_stats import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "proj_dir = '/Users/nikhil/code/git_repos/compare-surf-tools/'\n",
    "data_dir = proj_dir + 'data/'\n",
    "fs60_dir = data_dir + 'fs60_group_stats/'\n",
    "demograph_file = 'ABIDE_Phenotype.csv'\n",
    "ants_file = 'ABIDE_ants_thickness_data.csv' #uses modified (mindboggle) dkt atlas with 31 ROIs\n",
    "fs53_file = 'ABIDE_fs5.3_thickness.csv'\n",
    "fs51_file = 'cortical_fs5.1_measuresenigma_thickavg.csv' \n",
    "fs60_lh_file = 'lh.aparc.thickness.table.test1' #'aparc_lh_thickness_table.txt' #'lh.aparc.thickness.table.test1'\n",
    "fs60_rh_file = 'rh.aparc.thickness.table.test1' #'aparc_rh_thickness_table.txt' #'rh.aparc.thickness.table.test1'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Global Vars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "subject_ID_col = 'SubjID'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of ants data (1101, 99)\n",
      "shape of stdized ants data (1101, 90)\n",
      "\n",
      "shape of fs53 data (976, 74)\n",
      "shape of stdized fs53 data (976, 74)\n",
      "\n",
      "shape of fs51 data (1112, 74)\n",
      "shape of stdized fs51 data (1112, 74)\n",
      "\n",
      "shape of fs60 data l: (1047, 36), r: (1047, 36)\n",
      "shape of left and right merge fs6.0 df (1047, 71)\n",
      "shape of stdized fs51 data (1047, 71)\n"
     ]
    }
   ],
   "source": [
    "# Demographics and Dx\n",
    "demograph = pd.read_csv(data_dir + demograph_file)\n",
    "demograph = demograph.rename(columns={'Subject_ID':subject_ID_col})\n",
    "\n",
    "# ANTs\n",
    "ants_data = pd.read_csv(data_dir + ants_file, header=2)\n",
    "print('shape of ants data {}'.format(ants_data.shape))\n",
    "ants_data_std = standardize_ants_data(ants_data, subject_ID_col)\n",
    "print('shape of stdized ants data {}'.format(ants_data_std.shape))\n",
    "print('')\n",
    "\n",
    "# FS\n",
    "fs53_data = pd.read_csv(data_dir + fs53_file)\n",
    "print('shape of fs53 data {}'.format(fs53_data.shape))\n",
    "fs53_data_std = standardize_fs_data(fs53_data, subject_ID_col)\n",
    "print('shape of stdized fs53 data {}'.format(fs53_data_std.shape))\n",
    "print('')\n",
    "\n",
    "fs51_data = pd.read_csv(data_dir + fs51_file)\n",
    "print('shape of fs51 data {}'.format(fs51_data.shape))\n",
    "fs51_data_std = standardize_fs_data(fs51_data, subject_ID_col)\n",
    "print('shape of stdized fs51 data {}'.format(fs51_data_std.shape))\n",
    "print('')\n",
    "\n",
    "fs60_lh_data = pd.read_csv(data_dir + fs60_lh_file, delim_whitespace=True)\n",
    "fs60_rh_data = pd.read_csv(data_dir + fs60_rh_file, delim_whitespace=True)\n",
    "print('shape of fs60 data l: {}, r: {}'.format(fs60_lh_data.shape,fs60_rh_data.shape))\n",
    "\n",
    "fs60_data_std = standardize_fs60_data(fs60_lh_data, fs60_rh_data, subject_ID_col)\n",
    "print('shape of stdized fs51 data {}'.format(fs60_data_std.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create master dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of datasets: 4\n",
      "Finding common subject and columns\n",
      "Number of common subjects and columns: 593, 63\n",
      "\n",
      "checking ants dataframe\n",
      "Shape of the dataframe based on common cols and subs (593, 63)\n",
      "Basic data check passed\n",
      "Shape of the concat dataframe (593, 64)\n",
      "\n",
      "checking fs60 dataframe\n",
      "Shape of the dataframe based on common cols and subs (593, 63)\n",
      "Basic data check passed\n",
      "Shape of the concat dataframe (1186, 64)\n",
      "\n",
      "checking fs53 dataframe\n",
      "Shape of the dataframe based on common cols and subs (593, 63)\n",
      "Basic data check passed\n",
      "Shape of the concat dataframe (1779, 64)\n",
      "\n",
      "checking fs51 dataframe\n",
      "Shape of the dataframe based on common cols and subs (593, 63)\n",
      "Basic data check passed\n",
      "Shape of the concat dataframe (2372, 64)\n",
      "Number of common ROIs 62\n"
     ]
    }
   ],
   "source": [
    "data_dict = {'ants' : ants_data_std,\n",
    "            'fs60' : fs60_data_std,\n",
    "            'fs53' : fs53_data_std,\n",
    "            'fs51' : fs51_data_std}\n",
    "\n",
    "na_action = 'drop' # options: ignore, drop; anything else will not use the dataframe for analysis. \n",
    "master_df, common_subs, common_roi_cols = combine_processed_data(data_dict, subject_ID_col, na_action)\n",
    "\n",
    "print('Number of common ROIs {}'.format(len(common_roi_cols)))\n",
    "\n",
    "# Add demographic columns to the master_df\n",
    "useful_demograph = demograph[[subject_ID_col,'SEX','AGE_AT_SCAN','DX_GROUP']].copy()\n",
    "_,useful_demograph[subject_ID_col] = useful_demograph[subject_ID_col].str.split('_', 1).str\n",
    "# master_df = pd.merge(master_df, useful_demograph, how='left', on=subject_ID_col)\n",
    "# print('\\nmaster df shape after adding demographic info {}'.format(master_df.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Correlation between pipelines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg cross correlation between ants & fs60 = 0.44\n",
      "\n",
      "Avg cross correlation between ants & fs53 = 0.48\n",
      "\n",
      "Avg cross correlation between ants & fs51 = 0.44\n",
      "\n",
      "Avg cross correlation between fs60 & fs53 = 0.91\n",
      "\n",
      "Avg cross correlation between fs60 & fs51 = 0.88\n",
      "\n",
      "Avg cross correlation between fs53 & fs51 = 0.91\n",
      "\n"
     ]
    }
   ],
   "source": [
    "possible_pairs = list(itertools.combinations(data_dict.keys(), 2))\n",
    "\n",
    "for pair in possible_pairs:\n",
    "    pipe1 = pair[0]\n",
    "    pipe2 = pair[1]\n",
    "    df1 = master_df[master_df['pipeline']==pipe1][[subject_ID_col]+common_roi_cols]\n",
    "    df2 = master_df[master_df['pipeline']==pipe2][[subject_ID_col]+common_roi_cols]\n",
    "\n",
    "    xcorr = cross_correlations(df1,df2,subject_ID_col)\n",
    "    print('Avg cross correlation between {} & {} = {:4.2f}\\n'.format(pipe1,pipe2,np.mean(xcorr)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compare ML performance "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running ML classifer on 4 pipelines\n",
      "Pipeline ants,  Accuracy mean:0.592, sd:0.063\n",
      "Pipeline fs60,  Accuracy mean:0.561, sd:0.051\n",
      "Pipeline fs53,  Accuracy mean:0.549, sd:0.057\n",
      "Pipeline fs51,  Accuracy mean:0.526, sd:0.061\n"
     ]
    }
   ],
   "source": [
    "input_cols = common_roi_cols\n",
    "outcome_col = 'DX_GROUP'\n",
    "clf = svm.SVC(kernel='linear')\n",
    "ml_perf = getClassiferPerf(master_df,input_cols,outcome_col,clf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Compare statsmodels performance "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running 62 mass-univariate logit statsmodels on 4 pipelines\n",
      "Shape of the stats_models results df (248, 4)\n"
     ]
    }
   ],
   "source": [
    "roi_cols = common_roi_cols\n",
    "covar_cols = ['SEX','AGE_AT_SCAN']\n",
    "outcome_col = 'DX_GROUP'\n",
    "stat_model = 'logit'\n",
    "sm_perf = getStatModelPerf(master_df,roi_cols,covar_cols,outcome_col,stat_model)\n",
    "print('Shape of the stats_models results df {}'.format(sm_perf.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
